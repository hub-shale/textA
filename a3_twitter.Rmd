---
title: "Twitter Sentiment"
author: "Shale"
date: "4/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(quanteda)
#devtools::install_github("quanteda/quanteda.sentiment") #not available currently through CRAN
library(quanteda.sentiment)
library(quanteda.textstats)
library(tidyverse)
library(tidytext)
library(lubridate)
library(wordcloud) #visualization of common words in the data set
library(reshape2)
library(DT)
```

# Loading & Further Cleaning

```{r}
raw_tweets <- read.csv("https://raw.githubusercontent.com/MaRo406/EDS_231-text-sentiment/main/dat/IPCC_tweets_April1-10_sample.csv", header=TRUE)

dat <- raw_tweets[,c(5,7)] # Extract Date and Title fields

tweets <- tibble(text = dat$Title,
                  id = seq(1:length(dat$Title)),
                 date = as.Date(dat$Date,'%m/%d/%y'))
```

A quick look:

```{r}
head(tweets$text, n = 10)
#simple plot of tweets per day

tweets %>%
  count(date) %>%
  ggplot(aes(x = date, y = n))+
  geom_line()
```

```{r}
#let's clean up the URLs from the tweets
clean_twt = tweets

clean_twt$text <- gsub("http[^[:space:]]*", "",clean_twt$text)
clean_twt$text <- gsub("@[^[:space:]]*", "", clean_twt$text)
clean_twt$text <- str_to_lower(clean_twt$text)

```


# Most Common Words by Day

```{r}
pop = clean_twt %>% 
  unnest_tokens(output = word, input = text, token = "words") %>%
  anti_join(stop_words, by = "word") %>% 
  group_by(date, word) %>% 
  summarise(daily_count = n()) %>% 
  slice_max(daily_count, n=10, with_ties = FALSE)
  

ggplot(data = pop, aes(x=daily_count, y=reorder(word, daily_count))) + 
  geom_bar(stat = "identity") +
  facet_wrap(facets = "date", scales = "free")
```

The words `ipcc`, `climate`, and `report` are consistently the most frequently used words per day, which makes sense in a query for "IPCC." There is a distinct pattern in the count of the most common words each day: on April 1-2 there are very few mentions, probably an indicator of fewer tweets overall that fit the query; April 3rd the numbers get higher, with the term `ipcc` showing up about 100 times. Count of these words max out on April 4-5, with many hundreds of uses of `ipcc`, `climate`, and `report`; then usage steadily declines again from April 6-10.

# Wordcloud

```{r}
#load sentiment lexicons
bing_sent <- get_sentiments('bing')
nrc_sent <- get_sentiments('nrc')

#tokenize tweets to individual words
words <- clean_twt %>%
  select(id, date, text) %>%
  unnest_tokens(output = word, input = text, token = "words") %>%
  anti_join(stop_words, by = "word") %>%
  left_join(bing_sent, by = "word") %>%
  left_join(
    tribble(
      ~sentiment, ~sent_score,
      "positive", 1,
      "negative", -1),
    by = "sentiment")
```


```{r}
words %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "green"),
                   max.words = 100)


```

# Most Tagged Accounts

```{r}
# using quanteda and corpus() for alternate analyses

corpus = corpus(dat$Title)

tokens = tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE) %>% 
  tokens_remove(stopwords("english")) %>% 
  tokens_remove("http[^[:space:]]*", valuetype = "regex") %>% 
  tokens_tolower()

tokens_at = tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE) %>% 
  tokens_keep(pattern = "@*")

dfm_at = dfm(tokens_at)

#this is useful!
tstat_freq <- textstat_frequency(dfm_at, n = 100)

tidy_at <- tidy(dfm_at) %>%
   count(term) %>%
   with(wordcloud(term, n, max.words = 25))

# Show the top 10 accounts
topten = data.frame(tstat_freq) %>% 
  filter(rank < 11) %>%
  select(-group) %>% 
  datatable()
topten
```

# Alternate Sentiment Comparison

```{r}
raw_sent <- raw_tweets[,c(5,7,11)] # Extract Date and Title fields

tweetsent <- tibble(text = raw_sent$Title,
                  id = seq(1:length(raw_sent$Title)),
                 date = as.Date(raw_sent$Date,'%m/%d/%y'),
                 sent = raw_sent$Sentiment)

# default sentiment
bwatch = tweetsent %>% 
  group_by(sent) %>% 
  summarise(count = n())

ggplot(bwatch, aes(x=sent,y=count))+
  geom_bar(stat = "identity", aes(fill = sent)) +
  ggtitle("Barplot of Sentiment in IPCC tweets (default Brandwatch calculation)")


# the comparison
tweets_sent <- words %>%
      mutate(sent_score = replace_na(sent_score, 0)) %>% 
      group_by(id) %>%
      summarize(
        sent_score = mean(sent_score, na.rm = T))

neutral <- length(which(tweets_sent$sent_score == 0))
positive <- length(which(tweets_sent$sent_score > 0))
negative <- length(which(tweets_sent$sent_score < 0))

# graph overall sentiments
Sentiment <- c("Positive","Neutral","Negative")
Count <- c(positive,neutral,negative)
output <- data.frame(Sentiment,Count)
output$Sentiment<-factor(output$Sentiment,levels=Sentiment)
ggplot(output, aes(x=Sentiment,y=Count))+
  geom_bar(stat = "identity", aes(fill = Sentiment))+
  scale_fill_manual("legend", values = c("Positive" = "green", "Neutral" = "black", "Negative" = "red"))+
  ggtitle("Barplot of Sentiment in IPCC tweets")
```

In a comparison of the default Brandwatch sentiment values and a manual calculation using the `bing` sentiment lexicon, there is a clear mismatch that highlights the ineffectiveness of the Brandwatch sentiment analysis. The primary problem with the Brandwatch sentiment is that there are 1435 tweets (out of a total of 2411) that were assigned no sentiment: not neutral, but rather just the equivalent of `NA`. Additionally, the Brandwatch analysis splits the ~1000 remaining data points into  not just `positive`, `negative`, and `neutral` categories, but also six other emotion categories (most prominently fear, joy, and sadness), which further thins out the data; in the end, this leaves only 2 tweets identified as negative and 1 as positive. In contrast, using the `bing` lexicon to identify all positive and negative words yields 1030 negative and 373 positive tweets. Additionally, by classifying all tweets that had no sentiment words (in addition to tweets that had equal amounts of positive and negative words) as neutral, most of the tweets that Brandwatch discarded as `NA` are instead able to be labeled as neutral, for a total of 995 neutral tweets (compared to Brandwatch's 28 neutral tweets).


